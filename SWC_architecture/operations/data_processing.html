

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>4.11. Data Processing System &mdash; GMT Software And Controls documentation</title>
  

  
  
    <link rel="shortcut icon" href="../../_static/favicon.ico"/>
  
  
  

  

  
  
    

  

  
  
    <link rel="stylesheet" href="../../_static/css/additional_style.css" type="text/css" />
  

  
    <link rel="stylesheet" href="../../_static/theme_overrides.css" type="text/css" />
  

  
        <link rel="index" title="Index"
              href="../../genindex.html"/>
        <link rel="search" title="Search" href="../../search.html"/>
    <link rel="top" title="GMT Software And Controls documentation" href="../../index.html"/>
        <link rel="up" title="4. Observatory Operation System" href="observatory_operations.html"/>
        <link rel="next" title="5. Telescope Control System" href="../tcs/tcs_introduction.html"/>
        <link rel="prev" title="4.10. Data Archiving System" href="data_archiving.html"/> 

  
  <script src="../../_static/js/modernizr.min.js"></script>

</head>

<body class="wy-body-for-nav" role="document">

   
  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search">
          

          
            <a href="../../index.html" class="icon icon-home"> GMT Software And Controls
          

          
            
            <img src="../../_static/logowhite.png" class="logo" />
          
          </a>

          
            
            
              <div class="version">
                1.9
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../../release_notes/index.html">Release Notes</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="../index.html">Architecture and Design</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="../introduction/swcs_introduction.html">1. Introduction</a></li>
<li class="toctree-l2"><a class="reference internal" href="../requirements/requirements.html">2. Requirements Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="../architecture/overall_architecture.html">3. Overall Architecture</a></li>
<li class="toctree-l2 current"><a class="reference internal" href="observatory_operations.html">4. Observatory Operation System</a><ul class="current">
<li class="toctree-l3"><a class="reference internal" href="overview.html">4.1. Operations Overview</a></li>
<li class="toctree-l3"><a class="reference internal" href="deployment.html">4.2. Operations Deployment</a></li>
<li class="toctree-l3"><a class="reference internal" href="subsystems.html">4.3. Operations Subsystems</a></li>
<li class="toctree-l3"><a class="reference internal" href="user_interface.html">4.4. Operations User Interface</a></li>
<li class="toctree-l3"><a class="reference internal" href="observing_tools.html">4.5. Observing Tools</a></li>
<li class="toctree-l3"><a class="reference internal" href="scheduling_system.html">4.6. Scheduling System</a></li>
<li class="toctree-l3"><a class="reference internal" href="sequencer.html">4.7. Sequencer</a></li>
<li class="toctree-l3"><a class="reference internal" href="laser_ao_safety.html">4.8. Laser AO Operations Safety</a></li>
<li class="toctree-l3"><a class="reference internal" href="quality_monitoring.html">4.9. Quality Monitoring System</a></li>
<li class="toctree-l3"><a class="reference internal" href="data_archiving.html">4.10. Data Archiving System</a></li>
<li class="toctree-l3 current"><a class="current reference internal" href="#">4.11. Data Processing System</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#subsystem-design">4.11.1. <em>Subsystem Design</em></a></li>
<li class="toctree-l4"><a class="reference internal" href="#pipeline-applications">4.11.2. <em>Pipeline Applications</em></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../tcs/tcs_introduction.html">5. Telescope Control System</a></li>
<li class="toctree-l2"><a class="reference internal" href="../services/observatory_services.html">6. Observatory Services</a></li>
<li class="toctree-l2"><a class="reference internal" href="../frameworks/component_frameworks.html">7. Frameworks</a></li>
<li class="toctree-l2"><a class="reference internal" href="../platform/platform.html">8. Platform</a></li>
<li class="toctree-l2"><a class="reference internal" href="../process/process_introduction.html">9. Process</a></li>
<li class="toctree-l2"><a class="reference internal" href="../risks/risks.html">10. Software and Control Risks</a></li>
<li class="toctree-l2"><a class="reference internal" href="../bibliography/bibliography.html">11. Bibliography</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../SWC_standards/index.html">Software and Controls Standards</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../software_development/index.html">Software Development</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../data_products/index.html">Data Products</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../glossary/swc_sys_glossary.html">Software and Controls Acronyms and Definitions</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" role="navigation" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">GMT Software And Controls</a>
        
      </nav>


      
      <div class="wy-nav-content">
        <div class="rst-content">
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../../index.html">Docs</a> &raquo;</li>
        
          <li><a href="../index.html">Architecture and Design</a> &raquo;</li>
        
          <li><a href="observatory_operations.html">4. Observatory Operation System</a> &raquo;</li>
        
      <li>4.11. Data Processing System</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="data-processing-system">
<span id="id1"></span><h1>4.11. Data Processing System<a class="headerlink" href="#data-processing-system" title="Permalink to this headline">¶</a></h1>
<p>Data from the observatory, whether related to science, engineering, environment,
facility, etc., usually require some form of data processing before they can be
further used in a workflow. The Data Processing System (DPS) provides a general
way to process operational data during observatory operations that is highly
customizable to meet runtime conditions. The types of data processing
potentially include those from instruments, sensors, wavefront processing,
detectors, telemetry, interlock and safety, database management, etc. The SWCS
Requirements derived from the SLR are:</p>
<table border="1" class="docutils" id="id4">
<caption><span class="caption-number">Table 4.8 </span><span class="caption-text">SWCS Data Processing Requirements (Level 3)</span><a class="headerlink" href="#id4" title="Permalink to this table">¶</a></caption>
<colgroup>
<col width="32%" />
<col width="68%" />
</colgroup>
<thead valign="bottom">
<tr class="row-odd"><th class="head">Title</th>
<th class="head">Statement</th>
</tr>
</thead>
<tbody valign="top">
<tr class="row-even"><td>Efficient Operations</td>
<td>The SWCS shall identify and define sequences for
instruments, telescope, and science, operations to
optimize on-sky observing efficiency and to comply
with GMT Efficiency Budget (GMT-SE-REF-00593).</td>
</tr>
<tr class="row-odd"><td>Telescope Operators,
Instrument Specialists,
and AO specialists</td>
<td>The SWCS shall be designed to efficiently support the
roles (operations, setup) of Telescope Operators,
Instrument Specialists, and AO specialists.</td>
</tr>
<tr class="row-even"><td>Quick Look</td>
<td>Provide software to facilitate near real-time
assessment of data quality for each instrument.</td>
</tr>
<tr class="row-odd"><td>Observing Program
Execution</td>
<td>The SWCS shall provide software tools to execute
Observing Programs.</td>
</tr>
<tr class="row-even"><td>Engineering Data
Management System</td>
<td>Provide hardware and software to collect, store,
retrieve, analyze, and display engineering data to
monitor the performance and health of the GMT system
and environmental information.</td>
</tr>
<tr class="row-odd"><td>Calibration
Efficiencies: AO, WFS,
daytime, nighttime,
routine, non-routine</td>
<td>The SWCS shall provide the capability to perform or
support calibrations of all subsystems, instruments,
AO, WFS, daytime, nighttime, routine, and non-routine
calibrations within the time window specified in their
respective requirements.</td>
</tr>
</tbody>
</table>
<p>Data processing refers generally to a system that takes input information or
data and performs operations (analysis, summary, conversion, etc.) and then
outputs other useful or desired information. The types of processing usually
involve any combination of the following operations: conversion, transformation,
analysis, aggregation, sorting, and validation. In the context of Observatory
Operations, the categories of processing more specifically mean the following:</p>
<blockquote>
<div><ul class="simple">
<li><em>Conversion</em> – Data conversion mostly repackages, renormalizes, or
reformats the input information in a different way required by software or
users, but otherwise preserves the context (i.e., a data table converts to
another data table) of the original input data. Data conversion is sometimes
useful as a communication conduit, or a thin interface, between different
software and hardware components. Other examples include conversions of:
file structure or type (e.g., from observatory standard to FITS file, ASCII
to binary, lossless data compression), astrometric coordinates (celestial
coordinates to pixel coordinates), spectrum wavelength scale (e.g., pixel to
wavelength), equinox coordinates (e.g., equinox B1950 to J2000), flux scale
(pixel counts to magnitude) etc.</li>
<li><em>Transformation</em> – Data transformation alters the input data in some
significant way, the goal of which is not to change the format or structure,
but rather to prune, improve (in some sense), or make corrections to the
data.  Examples of data transformation involve: bad pixel interpolation or
masking, image un-distortion, shifting, binning, rotation, magnification,
image (de)convolution, smoothing, data filtering, feature subtraction (sky
lines in spectroscopy), bias subtraction, flatfielding, etc. Data
transformation can either be atomic operations or highly complex, involving
a series of steps.  The creation of an IFU data cube is an example of a
complex transformation. It involves data (spectral) extraction, a change in
the data structure, and data combination. Both the input and output may be
in FITS data format, but the output is in data cube form instead of the
original 2-D image of spectra. The output is a much more useful format for
quick-look assessment of the data quality compared with the data in its
native, recorded, state.</li>
<li><em>Analysis</em> – Data analysis involves interpretation, inference, synthesis,
summary, and/or numerical computation, of input information that on output
produces entirely new information. This category includes both statistical
and numerical analysis. Statistical analysis involves summary of, as well as
inference from data. Examples of numerical analysis are linear algebra
operations, optimization of large numbers of variables, interpolation, etc.
Common uses of analysis in observatory operations include: estimation of
background noise, signal-to-noise of sources, centroid mean, regression,
seeing statistics, statistical analysis or cross correlation of telemetry,
source or feature extraction, matrix inversions (e.g., wavefront sensing
applications), equation solving, model generation (e.g., AO PSF simulations,
image or spectra creation), noise generation, and optimization of telescope
scheduling.</li>
<li><em>Aggregation</em> – Aggregation takes multiple data sets of similar context,
and either combines them in some way, or extends/appends the data set.
Examples include science image and spectra combination (e.g., mosaic
creation), data reduction and calibration (bias frame combinations, darks,
flats, etc.), merging telemetry data tables (e.g., for use in TPoint), etc.</li>
<li><em>Sorting</em> – Sorting involves reorganizing an ordered sequence of data into
another ordered sequence, following some numerical weights or rules.
Examples include schedule ranking based on parameter values, sorting by
proximity to coordinate, etc.</li>
<li><em>Validation</em> – This process validates that the data taken are useful and
may involve testing the integrity (data can be read correctly), completeness
(e.g., having all supporting data), correctness (e.g., data format, pointing
to correct object/field, proper filter), quality (e.g., high S/N, adequate
PSF Strehl or S/N), and absence of errors.</li>
</ul>
</div></blockquote>
<div class="section" id="subsystem-design">
<h2>4.11.1. <em>Subsystem Design</em><a class="headerlink" href="#subsystem-design" title="Permalink to this headline">¶</a></h2>
<p>The DPS, as with other OPS components, consists of a server and visualization,
sequencing, diagnosis, workflow, management, and hardware packages. The DPS is
designed according to a software pipeline pattern, meaning that each pipeline
consists of filters (processing elements), connected in series, where the output
of one filter feeds into the input of the next. The relationship between the
server, pipelines, and filter (processing elements) is shown graphically in
<a class="reference internal" href="#data-processing-system-workflow"><span class="std std-numref">Figure 4.18</span></a>. Pipelines allow the functionality
of the system to grow, evolve and adapt easily and dynamically with new
instruments or desired capabilities without having to recompile from source
code. Pipelines integrate directly into automated processes of the observatory
using only simple software wrappers or interfaces, and enable the observatory
staff to compose new operational recipes from existing pipelines. Furthermore,
experience has shown that wrapping pipeline filters can expedite software
documentation.</p>
<p>Instrument data pipelines are an especially good application for DPS modeling.
Each data pipeline can be created for each instrument or detector based
subsystem. Pipelines include recipes for quick-look, calibration, and end-to-end
data reduction. For each instrument that has multiple operating modes but share
many similarities, filters can be combined based on recipes that are customized
to each observing mode. The result of the execution of a recipe is a set of
observing and calibration data.</p>
<div class="figure" id="id5">
<span id="data-processing-system-workflow"></span><img alt="../../_images/data_processing_system.png" src="../../_images/data_processing_system.png" />
<p class="caption"><span class="caption-number">Fig. 4.18 </span><span class="caption-text">The Data Processing System, showing the workflow and relationship between
the Server and the Pipelines in the DPS.  The data processing pipelines are
made up of filters (labeled as processing elements) that are connected in
series.  Each pipeline produces a specific data product upon output.
Although presented as linear pipelines, in reality filters are application
modules that are used or shared among multiple data pipelines, often
simultaneously.  Multiple data pipelines may be running in parallel, and
multiple copies of the same pipeline may be invoked, at any given time.</span></p>
</div>
<p>As illustrated in <a class="reference internal" href="#data-processing-system-workflow"><span class="std std-numref">Figure 4.18</span></a>, at the
highest level, the DPS follows a client/server model for the purpose of
distributed computing. The DPS therefore comprises a Server and Processing
Pipelines, their roles being:</p>
<blockquote>
<div><ul class="simple">
<li><em>The Pipeline Server</em> – The pipeline server is the access point into the
DPS by clients, which make job requests to initiate job processes. The
server manages and orchestrates all computation workflows. As discussed
earlier, the purpose of the server-client model is to relieve clients from
having to know about the implementation, the computation details, and the
efforts needed to perform a process. If a process is computationally
intensive and requires GPU or parallel data processing, it is the
responsibility of the server to ensure that enough resources are allocated
to that process. Each process can trigger multiple pipelines sequentially or
in parallel, overseen by the server. The server knows when all the data from
the different parallel processing threads complete, so that the process is
ready to execute the next pipeline in the workflow. Furthermore, users or
software may create, spawn anew, or reconfigure data reduction pipelines
on-the-fly, by rearranging processing elements, via a pipeline (workflow)
editor (analogous to Sequence editors).  This enables users to adapt to
changing runtime situations trivially without having to learn the
programming environment.</li>
<li><em>Pipelines and Filters / Processing Elements</em> – In the DPS, there are
several categories of data processing pipelines that are natural to
Observatory Operations, as elaborated in <a class="reference internal" href="#pipeline-applications"><span class="std std-ref">Pipeline Applications</span></a>.  Each
pipeline produces a specific form of data product, such as reduced FITS
images (i.e., bias, dark, and flatfield corrected), data blocks, look-up
tables of flexure and astrometric maps. Any client (i.e., software or user),
can access all the data pipelines, as well as the individual filters
(<a class="reference internal" href="#data-processing-system-workflow"><span class="std std-numref">Figure 4.18</span></a>), directly via the
server. The difference between pipelines and processing modules is that
processing elements may be indivisible software tools that come as
commercial products or already pre-assembled (e.g., SExtractor <a class="reference internal" href="../bibliography/bibliography.html#bear96" id="id2">[BeAr96]</a>).
All such modular tools form the basis of the Common Framework libraries
(<a class="reference internal" href="../frameworks/component_frameworks.html#component-frameworks"><span class="std std-ref">Frameworks</span></a>), which the SWCS uses to build other tools or
software pipelines.  Whenever possible, the filters will be based on tools
and applications that are commonly used in astronomy, already part of the
Linux operating system, open-source tools, or pre- existing commercial
software. A user (or a software tool) can create new pipelines, and can
modify existing ones, by rearranging the filters via a pipeline user
interface to produce a data product.</li>
</ul>
</div></blockquote>
</div>
<div class="section" id="pipeline-applications">
<span id="id3"></span><h2>4.11.2. <em>Pipeline Applications</em><a class="headerlink" href="#pipeline-applications" title="Permalink to this headline">¶</a></h2>
<p>For Observatory Operations, the types of pipelines generally fall into the
categories of signal processing, statistics, astrometry, coordinate transform,
image matching, data reduction and calibration, and model synthesis. Each of
those pipeline categories is summarized here briefly:</p>
<blockquote>
<div><ul class="simple">
<li><em>Signal Processing</em> – The signal processing pipeline handles recording,
measurements, shaping, or analysis of signals, including time varying or
spatially varying signals. Some of the most common signals include:
temperature, pressure, encoder positions, images, and spectra. Examples of
the type of pipeline include: telemetry extraction and look-up table
generation, automated telescope pointing analysis and pointing model
creation, filtering of data stream (e.g., encoder readouts), image
enhancement, noise reduction, feature detection or extraction from images or
spectra for creating data cubes, etc.</li>
<li><em>Statistics</em> – In addition to performing basic statistics, statistical
pipelines perform all the pre- processing and data extraction necessary. For
instance, computing the background sky and noise level of an image or a
spectrum may require source detection and masking.</li>
<li><em>Astrometry</em> – Given an asterism of stars and galaxies in an image, and a
large database of astronomical catalog of objects, this pipeline performs
astrometric matching to attach a coordinate system to the image, accounting
for geometric distortions. In addition to positions, asterism matching can
also involve relative brightness of stars and galaxies as well as their
colors.</li>
<li><em>Coordinate Transform</em> – Solves for and evaluates transformations between
two different coordinate systems, whether in images or in spectra. This is
often used to facilitate accurate alignment of images or spectra, or to
solve for wavelength solutions.</li>
<li><em>Image Matching</em> – The Image Matching pipeline automatically figures out
the alignment between two images and matches them, either via PSF matching
or flux scaling. While image matching may use the coordinate transformation
pipeline to register the images as part of the process, additional uses of
the image-matching pipeline may involve image co-addition or subtraction,
where it is also necessary to match the PSF and intensity scaling, or some
other criteria.</li>
<li><em>Data Reduction and Calibration</em> – This pipeline removes instrumental
signatures from engineering and science detectors and sensors. Data
reduction and calibration pipelines include image reduction (bias, dark,
flat fielding), and spectroscopy reduction (sky line subtraction, wavelength
calibration, spectral response correction). It is the first step toward many
applications, including quick look and S/N calculation purposes, for queue
observing to validate the quality of data, and for creating image cubes for
IFU data.</li>
<li><em>Model Synthesis</em> – A model synthesis pipeline facilitates the creation of
artificial models for exposure time calculations. The pipeline helps to
generate AO PSFs based on the locations of guide stars in a detector field
of view relative to the science targets, and applies the PSFs to galaxy and
spectral models to generate realistic images. Details of this application
are discussed in <a class="reference internal" href="observing_tools.html#observing-tools"><span class="std std-ref">Observing Tools</span></a>.</li>
<li><em>Data Trending</em> – The data trending pipeline facilitates discovery of
correlations in the data with time, telescope pointing position, or between
parameters. This may involve automated or supervised extraction and analysis
of telemetry, quality monitoring, telescope flexure and pointing model data.</li>
</ul>
</div></blockquote>
</div>
</div>


           </div>
           <div class="articleComments">
            
           </div>
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="../tcs/tcs_introduction.html" class="btn btn-neutral float-right" title="5. Telescope Control System" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="data_archiving.html" class="btn btn-neutral" title="4.10. Data Archiving System" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2020, contributors.

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/snide/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  

    <script type="text/javascript">
        var DOCUMENTATION_OPTIONS = {
            URL_ROOT:'../../',
            VERSION:'1.9.1',
            COLLAPSE_INDEX:false,
            FILE_SUFFIX:'.html',
            HAS_SOURCE:  true,
            SOURCELINK_SUFFIX: '.txt'
        };
    </script>
      <script type="text/javascript" src="../../_static/jquery.js"></script>
      <script type="text/javascript" src="../../_static/underscore.js"></script>
      <script type="text/javascript" src="../../_static/doctools.js"></script>
      <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

  

  
  
    <script type="text/javascript" src="../../_static/js/theme.js"></script>
  

  
  
  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.StickyNav.enable();
      });
  </script>
   

</body>
</html>